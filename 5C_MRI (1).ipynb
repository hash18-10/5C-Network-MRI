{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd6f594",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c11f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7858 images and 7858 masks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the path to the data directory\n",
    "data_dir = r'C:\\Users\\VIVITHA NISANTHINI\\Downloads\\Data'\n",
    "\n",
    "# Get the list of all .tif (case insensitive) files in the directory and its subdirectories\n",
    "all_files = glob.glob(os.path.join(data_dir, '**', '*.tif'), recursive=True) + glob.glob(os.path.join(data_dir, '**', '*.TIF'), recursive=True)\n",
    "\n",
    "# Separate the files into images and masks\n",
    "image_paths = sorted([f for f in all_files if '_mask' not in f])\n",
    "mask_paths = sorted([f for f in all_files if '_mask' in f])\n",
    "\n",
    "# Print the number of images and masks found to ensure everything is working correctly\n",
    "print(f\"Found {len(image_paths)} images and {len(mask_paths)} masks\")\n",
    "\n",
    "\n",
    "# Split dataset into 80% training and 20% testing sets\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# CLAHE preprocessing\n",
    "def apply_clahe(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(image)\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_data(image_paths, mask_paths):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = apply_clahe(img)\n",
    "        img = cv2.resize(img, (256, 256)) / 255.0\n",
    "        mask = cv2.resize(mask, (256, 256)) / 255.0\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "train_images, train_masks = load_data(train_images, train_masks)\n",
    "test_images, test_masks = load_data(test_images, test_masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed09f5f",
   "metadata": {},
   "source": [
    "### 2. Model Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707809a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1759bf",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand dimensions to add channel for grayscale images\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "train_masks = np.expand_dims(train_masks, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "test_masks = np.expand_dims(test_masks, axis=-1)\n",
    "\n",
    "# Train the models\n",
    "nested_unet.fit(train_images, train_masks, validation_data=(test_images, test_masks), epochs=10, batch_size=4)\n",
    "attention_unet.fit(train_images, train_masks, validation_data=(test_images, test_masks), epochs=10, batch_size=4)\n",
    "\n",
    "# Evaluate the models using DICE Score\n",
    "def dice_score(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "nested_unet_dice = dice_score(test_masks, nested_unet.predict(test_images))\n",
    "attention_unet_dice = dice_score(test_masks, attention_unet.predict(test_images))\n",
    "\n",
    "print(f\"Nested U-Net DICE Score: {nested_unet_dice}\")\n",
    "print(f\"Attention U-Net DICE Score: {attention_unet_dice}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81fdd4",
   "metadata": {},
   "source": [
    "### 4. Web Application Development\n",
    "- FAST API Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0dbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    # Read image from file\n",
    "    contents = await file.read()\n",
    "    nparr = np.frombuffer(contents, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
    "    img = apply_clahe(img)\n",
    "    img = cv2.resize(img, (256, 256)) / 255.0\n",
    "    img = np.expand_dims(img, axis=(0, -1))\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = attention_unet.predict(img)\n",
    "    return {\"prediction\": prediction.tolist()}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e82d76",
   "metadata": {},
   "source": [
    "- Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05baeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "st.title(\"Brain MRI Metastasis Segmentation\")\n",
    "uploaded_file = st.file_uploader(\"Choose a brain MRI image...\", type=\"jpg\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption='Uploaded MRI Image.', use_column_width=True)\n",
    "    \n",
    "    # Make a request to the FastAPI server\n",
    "    files = {'file': uploaded_file.getvalue()}\n",
    "    response = requests.post(\"http://localhost:8000/predict/\", files=files)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        prediction = np.array(response.json()[\"prediction\"])\n",
    "        st.image(prediction[0], caption='Metastasis Segmentation Result', use_column_width=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda0f52-2b3f-4262-88a3-6ba73517e16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
